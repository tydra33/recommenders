{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UserItemData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserItemData:\n",
    "    def __init__(self, path, start_date=None, end_date=None, min_ratings=0):\n",
    "        self.data = pd.read_csv(path, sep=\"\\t\", encoding=\"latin-1\")\n",
    "        self.filter_by_date(start_date, end_date)\n",
    "        self.filter_by_ratings(min_ratings)\n",
    "    \n",
    "    def get_date(self):\n",
    "        data = self.data\n",
    "        return pd.to_datetime((data.date_year*10000+data.date_month*100+data.date_day).apply(str),format='%Y%m%d')  \n",
    "    \n",
    "    def filter_by_date(self, start_date, end_date):\n",
    "        if not start_date and not end_date:\n",
    "            return\n",
    "        \n",
    "        dates = self.get_date()\n",
    "        \n",
    "        if start_date:\n",
    "            s_date_vals = start_date.split(\".\")\n",
    "            s_year = s_date_vals[2]\n",
    "            s_month = s_date_vals[1]\n",
    "            s_day = s_date_vals[0]\n",
    "\n",
    "            start_date = pd.Timestamp(f\"{s_year}-{s_month}-{s_day}\")\n",
    "            self.data = self.data[dates >= start_date]\n",
    "\n",
    "        if end_date:\n",
    "            e_date_vals = end_date.split(\".\")\n",
    "            e_year = e_date_vals[2]\n",
    "            e_month = e_date_vals[1]\n",
    "            e_day = e_date_vals[0]\n",
    "\n",
    "            end_date = pd.Timestamp(f\"{e_day}-{e_month}-{e_year}\")\n",
    "            self.data = self.data[dates <= end_date]\n",
    "    \n",
    "    # count the frequency of a movieID\n",
    "    def filter_by_ratings(self, min_ratings):\n",
    "        self.data[\"ratingsNum\"] = self.data.groupby('movieID')['rating'].transform('count')\n",
    "        self.data = self.data[self.data[\"ratingsNum\"] >= min_ratings]\n",
    "        \n",
    "    def nratings(self):\n",
    "        return len(self.data.index)\n",
    "    \n",
    "    def add_ratings(self, new_data):\n",
    "        rows = []\n",
    "        for items in new_data:\n",
    "            user_id, movie_id, rating = items\n",
    "            new_row = {}\n",
    "            \n",
    "            new_row[\"userID\"] = user_id\n",
    "            new_row[\"movieID\"] = movie_id\n",
    "            new_row[\"rating\"] = rating\n",
    "            \n",
    "            new_row[\"date_day\"] = \"13\"\n",
    "            new_row[\"date_month\"] = \"12\"\n",
    "            new_row[\"date_year\"] = \"2009\"\n",
    "            new_row[\"date_hour\"] = \"13\"\n",
    "            new_row[\"date_minute\"] = \"13\"\n",
    "            new_row[\"date_second\"] = \"13\"\n",
    "            \n",
    "            rows.append(new_row)\n",
    "        \n",
    "        my_df = pd.DataFrame.from_dict(rows, orient='columns')\n",
    "        self.data = self.data.append(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855598\n",
      "73657\n"
     ]
    }
   ],
   "source": [
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "print(uim.nratings())\n",
    "\n",
    "uim = UserItemData('data/user_ratedmovies.dat', start_date = '12.1.2007', end_date='16.2.2008', min_ratings=100)\n",
    "print(uim.nratings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieData():\n",
    "    def __init__(self, path):\n",
    "        self.data = pd.read_table(path, encoding='latin-1')\n",
    "\n",
    "    def get_title(self, ajdi):\n",
    "        row = self.data[self.data[\"id\"] == ajdi]\n",
    "        return str(row[\"title\"].item())\n",
    "    \n",
    "    def get_all_movies(self):\n",
    "        return self.data[\"id\"].unique()\n",
    "    \n",
    "    def get_genre_info(self, path):\n",
    "        self.genres_table = pd.read_table(path, encoding='latin-1')\n",
    "        keep = [\"id\", \"title\"]\n",
    "        \n",
    "        filtered_data = self.data[keep].set_index('id')\n",
    "        genres = self.genres_table.groupby('movieID')['genre'].apply(list)        \n",
    "        return filtered_data.merge(genres.to_frame(), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy story\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "print(md.get_title(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPredictor:\n",
    "    def __init__(self, min_rating, max_rating):\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.uim = X\n",
    "\n",
    "    def predict(self, user_id):\n",
    "        md = MovieData('data/movies.dat')\n",
    "\n",
    "        data = self.uim.data[self.uim.data[\"userID\"] == user_id]\n",
    "        keep = [\"movieID\", \"rating\"]\n",
    "        data = data[keep]\n",
    "\n",
    "        all_movies = md.get_all_movies()\n",
    "        temp_user_table = pd.DataFrame(\n",
    "            columns=[\"movieID\", \"rating\"])\n",
    "        temp_user_table[\"movieID\"] = all_movies\n",
    "\n",
    "        user_table = pd.concat([temp_user_table, data])\n",
    "        user_table = user_table.drop_duplicates(\n",
    "            subset=[\"movieID\"], keep=\"last\")\n",
    "        user_table = user_table.fillna(\n",
    "            value=random.randint(self.min_rating, self.max_rating))\n",
    "        user_table = user_table.set_index(\"movieID\")\n",
    "\n",
    "        return user_table.to_dict()[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "Film: Toy story, ocena: 4.0\n",
      "Film: Grumpy Old Men, ocena: 4.0\n",
      "Film: Money Train, ocena: 4.0\n",
      "Film: The Usual Suspects, ocena: 4.0\n",
      "Film: City Hall, ocena: 4.0\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "rp = RandomPredictor(1, 5)\n",
    "rp.fit(uim)\n",
    "pred = rp.predict(78)\n",
    "print(type(pred))\n",
    "items = [1, 3, 20, 50, 100]\n",
    "for item in items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(item), pred[item]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender: \n",
    "    def __init__(self, pred):\n",
    "        self.pred = pred\n",
    "        \n",
    "        \n",
    "    def fit(self, X): \n",
    "        self.uim = X \n",
    "        self.pred.fit(X)\n",
    "    \n",
    "    \n",
    "    def recommend(self, user_id, n=10, rec_seen=True):\n",
    "        slovar = self.pred.predict(user_id)\n",
    "        watched = self.uim.data[self.uim.data[\"userID\"] == user_id].movieID.values\n",
    "        top_rated = sorted(slovar, key=slovar.get, reverse=True)\n",
    "        \n",
    "        if not rec_seen:\n",
    "            top_rated = [x for x in top_rated if x not in watched]\n",
    "        \n",
    "        return[(key, slovar[key]) for key in top_rated[:n]]\n",
    "    \n",
    "    \n",
    "    def recommend_for_val(self, user_id, n):\n",
    "        user_avg_score = self.pred.user_mean_ratings[user_id]\n",
    "        preds = self.pred.predict(user_id)\n",
    "        temp_df = self.pred.uim.data\n",
    "        user_movies = set(temp_df[temp_df['userID'] == user_id]['movieID'])\n",
    "        \n",
    "        for movie in user_movies:\n",
    "            preds.pop(movie, None)\n",
    "        \n",
    "        result = {key: value for key, value in preds.items() if value >= user_avg_score}\n",
    "        return sorted(result.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    \n",
    "    def calc_p(self, user_id, n):\n",
    "        recommended = self.recommend_for_val(user_id, n)\n",
    "        recommended = set([key for key, value in recommended])\n",
    "        \n",
    "        fil = self.filtered_td['userID'] == user_id\n",
    "        watched = set(self.filtered_td[fil]['movieID'].values)\n",
    "        \n",
    "        intersection = set.intersection(recommended, watched)\n",
    "        \n",
    "        if len(recommended):\n",
    "            precision = len(intersection) / len(recommended)\n",
    "        else:\n",
    "            precision = 0\n",
    "        \n",
    "        recall = len(intersection) / len(watched)\n",
    "        return precision, recall\n",
    "        \n",
    "    \n",
    "    def calc_m(self, pred, real):\n",
    "        mse = 0\n",
    "        mae = 0\n",
    "\n",
    "        for movie in real:\n",
    "            mse += (real[movie] - pred[movie])**2\n",
    "            mae += abs(real[movie] - pred[movie])\n",
    "        \n",
    "        return mse, mae, len(real)\n",
    "        \n",
    "    \n",
    "    def evaluate(self, test_data, n):\n",
    "        self.test_data = test_data.data[['userID', 'movieID','rating']]\n",
    "        train_uids = np.unique(self.pred.uim.data['userID'].values)\n",
    "        train_mids = set(self.pred.data['movieID'].values)\n",
    "        \n",
    "        self.filtered_td = self.test_data[self.test_data['movieID'].isin(train_mids)]\n",
    "        test_uids = np.unique(self.filtered_td['userID'].values)\n",
    "        \n",
    "        users = np.intersect1d(test_uids, train_uids)\n",
    "\n",
    "        self.test_ratings = {}\n",
    "        for user in users:\n",
    "            mask = (self.filtered_td['userID'] == user)\n",
    "            self.test_ratings[user] = dict(zip(self.filtered_td[mask]['movieID'].values, self.filtered_td[mask]['rating'].values))\n",
    "        \n",
    "        \n",
    "        mse = 0\n",
    "        mae = 0\n",
    "        size = 0\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        for user in users:\n",
    "            pred =  self.pred.predict(user)\n",
    "            real = self.test_ratings[user]\n",
    "            mse_, mae_, n_ = self.calc_m(pred, real)\n",
    "            mse += mse_\n",
    "            mae += mae_\n",
    "            size += n_\n",
    "            \n",
    "            precision_, recall_ = self.calc_p(user, n)\n",
    "            precision += precision_\n",
    "            recall += recall_\n",
    "        \n",
    "        mse = mse / size\n",
    "        mae = mae / size\n",
    "        precision /= size\n",
    "        recall /= size\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "             \n",
    "        return mse, mae, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7284717901938453 0.6305249422642825 0.10034102028289822 0.14149272901587545 0.11741557853882702\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000, end_date='1.1.2008')\n",
    "rp = SlopeOnePredictor()\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "\n",
    "uim_test = UserItemData('data/user_ratedmovies.dat', min_ratings=200, start_date='2.1.2008')\n",
    "mse, mae, precision, recall, f = rec.evaluate(uim_test, 20)\n",
    "print(mse, mae, precision, recall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: Toy story, ocena: 5.0\n",
      "Film: Jumanji, ocena: 5.0\n",
      "Film: Grumpy Old Men, ocena: 5.0\n",
      "Film: Waiting to Exhale, ocena: 5.0\n",
      "Film: Father of the Bride Part II, ocena: 5.0\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "rp = RandomPredictor(1, 5)\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AveragePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePredictor:\n",
    "    def __init__(self, b):\n",
    "        self.b = b\n",
    "    \n",
    "    def get_avg(self, data, movie_id):\n",
    "        n = data[data[\"movieID\"] == movie_id][\"rating\"].values\n",
    "        vs = n.sum()\n",
    "        n = len(n)\n",
    "        return (vs + self.b * self.g_avg) / (n + self.b)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.data = X.data        \n",
    "        \n",
    "    def predict(self, user_id):\n",
    "        result = {}\n",
    "        self.g_avg = self.data[\"rating\"].mean()\n",
    "        \n",
    "        for movie_id in set(self.data[\"movieID\"].values):\n",
    "            result[movie_id] = self.get_avg(self.data, movie_id)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: Brother Minister: The Assassination of Malcolm X, ocena: 5.0\n",
      "Film: Synthetic Pleasures, ocena: 5.0\n",
      "Film: Gabbeh, ocena: 5.0\n",
      "Film: Storefront Hitchcock, ocena: 5.0\n",
      "Film: Ko to tamo peva, ocena: 5.0\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "rp = AveragePredictor(0)\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: The Usual Suspects, ocena: 4.225944245560473\n",
      "Film: The Godfather: Part II, ocena: 4.146907937910189\n",
      "Film: Cidade de Deus, ocena: 4.116538340205236\n",
      "Film: The Dark Knight, ocena: 4.10413904093503\n",
      "Film: 12 Angry Men, ocena: 4.103639627096175\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "rp = AveragePredictor(100)\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViewsPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewsPredictor:\n",
    "    def fit(self, X):\n",
    "        self.data = X.data\n",
    "\n",
    "    def predict(self, user_id):\n",
    "        self.data[\"ratingsNum\"] = self.data.groupby('movieID')['rating'].transform('count')\n",
    "        result = self.data.drop_duplicates(subset=['movieID'], keep='first')\n",
    "        \n",
    "        keep=[\"movieID\", \"ratingsNum\"]\n",
    "        result = result[keep]\n",
    "        result = result.set_index(\"movieID\")\n",
    "        \n",
    "        return result.to_dict()[\"ratingsNum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: The Lord of the Rings: The Fellowship of the Ring, ocena: 1576\n",
      "Film: The Lord of the Rings: The Two Towers, ocena: 1528\n",
      "Film: The Lord of the Rings: The Return of the King, ocena: 1457\n",
      "Film: The Silence of the Lambs, ocena: 1431\n",
      "Film: Shrek, ocena: 1404\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "rp = ViewsPredictor()\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STDPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STDPredictor:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    def filter_by_ratings(self):\n",
    "        self.data[\"ratingsNum\"] = self.data.groupby('movieID')['rating'].transform('count')\n",
    "        self.data = self.data[self.data[\"ratingsNum\"] >= self.n]\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.data = X.data\n",
    "        self.filter_by_ratings()\n",
    "        \n",
    "    def predict(self, user_id):\n",
    "        return self.data.groupby(\"movieID\")[\"rating\"].std().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: Plan 9 from Outer Space, ocena: 1.3449520951495717\n",
      "Film: The Passion of the Christ, ocena: 1.281493459525735\n",
      "Film: The Texas Chainsaw Massacre, ocena: 1.235349321908819\n",
      "Film: Jackass Number Two, ocena: 1.2189769976366684\n",
      "Film: White Chicks, ocena: 1.1899581424297319\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat')\n",
    "rp = STDPredictor(100)\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ItemBasedPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import itertools\n",
    "\n",
    "# values are a bit different but the results are the same so it's fineee\n",
    "class ItemBasedPredictor:\n",
    "    def __init__(self, min_values=0, threshold=0):\n",
    "        self.min_values = min_values\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    \n",
    "    def similarity(self, p1, p2):\n",
    "        users1 = self.data[self.data[\"movieID\"] == p1][\"userID\"].values\n",
    "        users2 = self.data[self.data[\"movieID\"] == p2][\"userID\"].values\n",
    "        c_users = np.intersect1d(users1, users2)\n",
    "        \n",
    "        if len(c_users) < self.min_values:\n",
    "            return 0\n",
    "        \n",
    "        table = self.user_ratings_w[self.user_ratings_w.index.isin(c_users)]\n",
    "        m1 = table[p1]\n",
    "        m2 = table[p2]\n",
    "        \n",
    "        sim = 1 - distance.cosine(m1, m2)\n",
    "        \n",
    "        if sim <= self.threshold:\n",
    "            return 0\n",
    "        return sim\n",
    "    \n",
    "    \n",
    "    # get weight\n",
    "    def get_w(self, x, user_id, means):\n",
    "            return x - means[user_id]\n",
    "    \n",
    "    \n",
    "    def sort(self, num):\n",
    "        return sorted(self.sims.items(), key=lambda x: x[1], reverse=True)[:num]\n",
    "       \n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.data = X.data\n",
    "        keep = ['userID', 'movieID' ,'rating']\n",
    "        self.data = self.data[keep]\n",
    "         \n",
    "        users = self.data.userID\n",
    "        movies = np.unique(self.data.movieID.values)\n",
    "\n",
    "        #         p1     p2    p3\n",
    "        # u1      x      x     x\n",
    "        # u2      x      x     x\n",
    "        # u3      x      x     x\n",
    "        self.user_ratings = self.data.pivot_table(index=['userID'], columns=['movieID'], values='rating')\n",
    "    \n",
    "        df_temp = self.data[['userID', 'rating']]\n",
    "        self.user_mean_ratings = pd.DataFrame.to_dict(df_temp.groupby('userID').mean())['rating']\n",
    "        self.user_ratings_w = self.user_ratings.apply(lambda row: self.get_w(row, row.name, self.user_mean_ratings), axis=1)\n",
    "        \n",
    "        self.sim_table = pd.DataFrame(index=movies, columns=movies)\n",
    "        self.sim_table[:] = 0\n",
    "        self.sims = {}\n",
    "        for pair in itertools.combinations(movies, 2):\n",
    "            m1, m2 = pair\n",
    "            sim = self.similarity(m1, m2)\n",
    "            \n",
    "            self.sims[(m1, m2)] = sim\n",
    "            self.sims[(m2, m1)] = sim\n",
    "            self.sim_table.loc[m1, m2] = sim\n",
    "            self.sim_table.loc[m2, m1] = sim\n",
    "    \n",
    "    \n",
    "    def trim_key(self, key, item):\n",
    "        if key[0] == item:\n",
    "            return key[1]\n",
    "        return key[0]\n",
    "    \n",
    "    \n",
    "    def similarItems(self, item, n):\n",
    "        pairs = dict((self.trim_key(key, item), value) for key, value in self.sims.items() if item in key)\n",
    "        return sorted(pairs.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "            \n",
    "            \n",
    "    def predict(self, user_id):\n",
    "        df = self.data\n",
    "        movies_rated = df[df[\"userID\"] == user_id]\n",
    "        filtered_sm = self.sim_table.loc[np.in1d(self.sim_table.index.values, movies_rated),]\n",
    "        mask = np.in1d(self.user_ratings_w.columns.values, movies_rated)\n",
    "        filtered_r = self.user_ratings_w.loc[user_id, mask].values\n",
    "        \n",
    "        weighted_ratings = filtered_sm.apply(lambda column: \n",
    "                                            np.sum(column * filtered_r) / np.sum(column) + self.user_mean_ratings[user_id] \n",
    "                                            if np.sum(column) else self.user_mean_ratings[user_id],\n",
    "                                            axis=0)\n",
    "        \n",
    "        new_ratings = weighted_ratings.to_dict()\n",
    "    \n",
    "        movies_rated = df[df['userID'] == user_id][['movieID','rating']]\n",
    "        predictions = dict(zip(movies_rated.movieID, movies_rated.rating))\n",
    "        for key, rating in new_ratings.items():\n",
    "            if key not in movies_rated:\n",
    "                predictions[key] = rating\n",
    "                \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podobnost med filmoma 'Men in black'(1580) in 'Ghostbusters'(2716):  0.23395523176756639\n",
      "Podobnost med filmoma 'Men in black'(1580) in 'Schindler's List'(527):  0\n",
      "Podobnost med filmoma 'Men in black'(1580) in 'Independence day'(780):  0.4246612584468762\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "rp = ItemBasedPredictor()\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "print(\"Podobnost med filmoma 'Men in black'(1580) in 'Ghostbusters'(2716): \", rp.similarity(1580, 2716))\n",
    "print(\"Podobnost med filmoma 'Men in black'(1580) in 'Schindler's List'(527): \", rp.similarity(1580, 527))\n",
    "print(\"Podobnost med filmoma 'Men in black'(1580) in 'Independence day'(780): \", rp.similarity(1580, 780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for 78: \n",
      "Film: Shichinin no samurai, ocena: 4.3557347903101595\n",
      "Film: The Usual Suspects, ocena: 4.354681728067836\n",
      "Film: The Silence of the Lambs, ocena: 4.335305303472516\n",
      "Film: Sin City, ocena: 4.2786871668991004\n",
      "Film: Monsters, Inc., ocena: 4.2175811369435205\n",
      "Film: The Incredibles, ocena: 4.2070985832817485\n",
      "Film: The Lord of the Rings: The Fellowship of the Ring, ocena: 4.152792107348347\n",
      "Film: Batman Begins, ocena: 4.146413806700199\n",
      "Film: Die Hard, ocena: 4.125915602232819\n",
      "Film: Rain Man, ocena: 4.071535242958551\n",
      "Film: The Lord of the Rings: The Return of the King, ocena: 4.020237449257013\n",
      "Film: A Beautiful Mind, ocena: 4.015142490064839\n",
      "Film: Good Will Hunting, ocena: 4.0092808069228205\n",
      "Film: The Lord of the Rings: The Two Towers, ocena: 3.941476305095594\n",
      "Film: Indiana Jones and the Last Crusade, ocena: 3.796976496378924\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions for 78: \")\n",
    "rec_items = rec.recommend(78, n=15, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film1: The Lord of the Rings: The Two Towers, Film2: The Lord of the Rings: The Return of the King, podobnost: 0.8439842148481417\n",
      "Film1: The Lord of the Rings: The Return of the King, Film2: The Lord of the Rings: The Two Towers, podobnost: 0.8439842148481417\n",
      "Film1: The Lord of the Rings: The Fellowship of the Ring, Film2: The Lord of the Rings: The Two Towers, podobnost: 0.8231885401761888\n",
      "Film1: The Lord of the Rings: The Two Towers, Film2: The Lord of the Rings: The Fellowship of the Ring, podobnost: 0.8231885401761888\n",
      "Film1: The Lord of the Rings: The Fellowship of the Ring, Film2: The Lord of the Rings: The Return of the King, podobnost: 0.8079374897442497\n",
      "Film1: The Lord of the Rings: The Return of the King, Film2: The Lord of the Rings: The Fellowship of the Ring, podobnost: 0.8079374897442497\n",
      "Film1: Kill Bill: Vol. 2, Film2: Kill Bill: Vol. 2, podobnost: 0.737234022438103\n",
      "Film1: Kill Bill: Vol. 2, Film2: Kill Bill: Vol. 2, podobnost: 0.737234022438103\n",
      "Film1: Star Wars, Film2: Star Wars: Episode V - The Empire Strikes Back, podobnost: 0.7021321132220318\n",
      "Film1: Star Wars: Episode V - The Empire Strikes Back, Film2: Star Wars, podobnost: 0.7021321132220318\n",
      "Film1: Ace Ventura: Pet Detective, Film2: The Mask, podobnost: 0.6616471778494046\n",
      "Film1: The Mask, Film2: Ace Ventura: Pet Detective, podobnost: 0.6616471778494046\n",
      "Film1: Star Wars: Episode V - The Empire Strikes Back, Film2: Star Wars: Episode VI - Return of the Jedi, podobnost: 0.5992253753778948\n",
      "Film1: Star Wars: Episode VI - Return of the Jedi, Film2: Star Wars: Episode V - The Empire Strikes Back, podobnost: 0.5992253753778948\n",
      "Film1: Independence Day, Film2: Star Wars: Episode I - The Phantom Menace, podobnost: 0.5610426219249997\n",
      "Film1: Star Wars: Episode I - The Phantom Menace, Film2: Independence Day, podobnost: 0.5610426219249997\n",
      "Film1: Ace Ventura: Pet Detective, Film2: Austin Powers: The Spy Who Shagged Me, podobnost: 0.5546511205201551\n",
      "Film1: Austin Powers: The Spy Who Shagged Me, Film2: Ace Ventura: Pet Detective, podobnost: 0.5546511205201551\n",
      "Film1: Star Wars, Film2: Star Wars: Episode VI - Return of the Jedi, podobnost: 0.5537849318137372\n",
      "Film1: Star Wars: Episode VI - Return of the Jedi, Film2: Star Wars, podobnost: 0.5537849318137372\n"
     ]
    }
   ],
   "source": [
    "sort_sims = rp.sort(20)\n",
    "for movies, sim in sort_sims:\n",
    "    print(f\"Film1: {md.get_title(movies[0])}, Film2: {md.get_title(movies[1])}, podobnost: {sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filmi podobni \"The Lord of the Rings: The Fellowship of the Ring\": \n",
      "Film: The Lord of the Rings: The Two Towers, ocena: 0.8231885401761888\n",
      "Film: The Lord of the Rings: The Return of the King, ocena: 0.8079374897442497\n",
      "Film: Star Wars: Episode V - The Empire Strikes Back, ocena: 0.2396194307349645\n",
      "Film: Star Wars, ocena: 0.21965586527074066\n",
      "Film: The Matrix, ocena: 0.21515552706880237\n",
      "Film: Raiders of the Lost Ark, ocena: 0.1994427670634501\n",
      "Film: The Usual Suspects, ocena: 0.18321188451910753\n",
      "Film: Blade Runner, ocena: 0.16399681315410275\n",
      "Film: Schindler's List, ocena: 0.16105905138148702\n",
      "Film: Monty Python and the Holy Grail, ocena: 0.15780453798519134\n"
     ]
    }
   ],
   "source": [
    "rec_items = rp.similarItems(4993, 10)\n",
    "print('Filmi podobni \"The Lord of the Rings: The Fellowship of the Ring\": ')\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for me: \n",
      "Film: Finding Nemo, ocena: 3.4855061079202\n",
      "Film: Monsters, Inc., ocena: 3.484138943119527\n",
      "Film: Toy story, ocena: 3.480419951075355\n",
      "Film: Le fabuleux destin d'Amélie Poulain, ocena: 3.4700922537364396\n",
      "Film: Shrek, ocena: 3.4694129326243957\n",
      "Film: Raiders of the Lost Ark, ocena: 3.4679712622505265\n",
      "Film: Eternal Sunshine of the Spotless Mind, ocena: 3.467773158719824\n",
      "Film: Star Wars: Episode V - The Empire Strikes Back, ocena: 3.4677368405739952\n",
      "Film: The Lord of the Rings: The Return of the King, ocena: 3.4677040329714743\n",
      "Film: Star Wars, ocena: 3.4667180503370916\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "rp = ItemBasedPredictor()\n",
    "rec = Recommender(rp)\n",
    "\n",
    "uim.add_ratings([[1, 589, 3], [1, 2446, 5], [1, 2810, 5], [1, 3717, 2.5], [1, 2012, 3], [1, 160, 2],\n",
    "                [1, 2013, 1], [1, 1394, 3.5], [1, 1396, 3.5], [1, 1408, 3.5], [1, 8924, 4], \n",
    "                [1, 8949, 4.5], [1, 8958, 4], [1, 8961, 4.5]])\n",
    "\n",
    "rec.fit(uim)\n",
    "print(\"Predictions for me: \")\n",
    "rec_items = rec.recommend(1, n=10, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope One Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlopeOnePredictor():\n",
    "    def fit(self, X):\n",
    "        self.uim = X\n",
    "        self.data = X.data\n",
    "        self.movies = np.unique(X.data.movieID.values)\n",
    "        \n",
    "        df_temp = self.data[['userID', 'rating']]\n",
    "        self.user_mean_ratings = pd.DataFrame.to_dict(df_temp.groupby('userID').mean())['rating']\n",
    "    \n",
    "    \n",
    "    def get_diff(self, m1, m2):\n",
    "        users_1 = self.data[self.data[\"movieID\"] == m1][\"userID\"].values\n",
    "        users_2 = self.data[self.data[\"movieID\"] == m2][\"userID\"].values\n",
    "        c_users = np.intersect1d(users_1, users_2)\n",
    "        \n",
    "        vector1 = self.data[(self.data[\"movieID\"] == m1) & (self.data[\"userID\"].isin(c_users))].rating\n",
    "        vector2 = self.data[(self.data[\"movieID\"] == m2) & (self.data[\"userID\"].isin(c_users))].rating\n",
    "        vector1 = vector1.reset_index(drop=True)\n",
    "        vector2 = vector2.reset_index(drop=True)\n",
    "        \n",
    "        difference = vector1.subtract(vector2)\n",
    "        return difference.sum() / len(c_users)\n",
    "    \n",
    "    \n",
    "    def get_n(self, m1, m2):\n",
    "        users_1 = self.data[self.data[\"movieID\"] == m1][\"userID\"].values\n",
    "        users_2 = self.data[self.data[\"movieID\"] == m2][\"userID\"].values\n",
    "        c_users = np.intersect1d(users_1, users_2)\n",
    "        \n",
    "        return len(c_users)\n",
    "    \n",
    "    \n",
    "    def predict(self, user):\n",
    "        userHasSeen = self.data[self.data[\"userID\"] == user][\"movieID\"].values\n",
    "        \n",
    "        predictions = {}\n",
    "        for movie in self.movies:\n",
    "            predictions[movie] = self.__predictOne(user, movie, userHasSeen)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def __predictOne(self, user, movie, userHasSeen):\n",
    "        pred = sum([(self.data[(self.data[\"movieID\"] == otherM) & (self.data[\"userID\"] == user)].iloc[0][\"rating\"] + self.get_diff(movie,otherM)) * self.get_n(movie,otherM) for otherM in userHasSeen[userHasSeen != movie]])\n",
    "        sumOfAllN = sum([self.get_n(movie,otherM) for otherM in userHasSeen[userHasSeen != movie]])\n",
    "        \n",
    "        if sumOfAllN == 0:\n",
    "            return self.data[self.data[\"userID\"] == user].rating.mean()\n",
    "        \n",
    "        return pred / sumOfAllN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for 78: \n",
      "Film: The Usual Suspects, ocena: 4.325079182263173\n",
      "Film: The Lord of the Rings: The Fellowship of the Ring, ocena: 4.155293229840448\n",
      "Film: The Lord of the Rings: The Return of the King, ocena: 4.153135076202185\n",
      "Film: The Silence of the Lambs, ocena: 4.127978169643881\n",
      "Film: Shichinin no samurai, ocena: 4.119790444913598\n",
      "Film: The Lord of the Rings: The Two Towers, ocena: 4.083325894849594\n",
      "Film: Indiana Jones and the Last Crusade, ocena: 3.9670398355464194\n",
      "Film: The Incredibles, ocena: 3.9664496674557546\n",
      "Film: Good Will Hunting, ocena: 3.963362387354114\n",
      "Film: Sin City, ocena: 3.942619137615212\n",
      "Film: Batman Begins, ocena: 3.9375326640077017\n",
      "Film: A Beautiful Mind, ocena: 3.9140940935239508\n",
      "Film: Rain Man, ocena: 3.9107819079644943\n",
      "Film: Monsters, Inc., ocena: 3.8819375978658006\n",
      "Film: Finding Nemo, ocena: 3.8807711131654794\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "rp = SlopeOnePredictor()\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "\n",
    "print(\"Predictions for 78: \")\n",
    "rec_items = rec.recommend(78, n=15, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridPredictor:\n",
    "    def __init__(self, slope_one, item_based, avg_pred):\n",
    "        self.so = slope_one\n",
    "        self.ib = item_based\n",
    "        self.ap = avg_pred\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.so.fit(X)\n",
    "        self.ib.fit(X)\n",
    "        self.ap.fit(X)\n",
    "        \n",
    "    def predict(self, user_id):\n",
    "        so_data = self.so.predict(user_id)\n",
    "        ib_data = self.ib.predict(user_id)\n",
    "        ap_data = self.ap.predict(user_id)\n",
    "        \n",
    "        movies = so_data.keys()\n",
    "        preds = {}\n",
    "        \n",
    "        for movie in movies:\n",
    "            preds[movie] = (so_data[movie] + ib_data[movie] + ap_data[movie])/3\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: The Usual Suspects, ocena: 4.311278518974733\n",
      "Film: Shichinin no samurai, ocena: 4.173534033030131\n",
      "Film: The Silence of the Lambs, ocena: 4.166374348258444\n",
      "Film: The Lord of the Rings: The Fellowship of the Ring, ocena: 4.1247457059145285\n",
      "Film: The Lord of the Rings: The Return of the King, ocena: 4.083025349250652\n",
      "Film: Sin City, ocena: 4.04150141849935\n",
      "Film: The Incredibles, ocena: 4.03517179295511\n",
      "Film: The Lord of the Rings: The Two Towers, ocena: 4.013769116650408\n",
      "Film: Batman Begins, ocena: 3.996277322964873\n",
      "Film: Monsters, Inc., ocena: 3.9850683879684383\n",
      "Film: Good Will Hunting, ocena: 3.963985125214793\n",
      "Film: Rain Man, ocena: 3.9468100652778144\n",
      "Film: Die Hard, ocena: 3.946727709564506\n",
      "Film: A Beautiful Mind, ocena: 3.9404428687612474\n",
      "Film: Indiana Jones and the Last Crusade, ocena: 3.9017846201129402\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "\n",
    "ib = ItemBasedPredictor()\n",
    "so = SlopeOnePredictor()\n",
    "ap = AveragePredictor(100)\n",
    "hybrid = HybridPredictor(so, ib, ap)\n",
    "\n",
    "rec = Recommender(hybrid)\n",
    "rec.fit(uim)\n",
    "\n",
    "rec_items = rec.recommend(78, n=15, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorizationPredictor:\n",
    "    def fit(self, X):\n",
    "        rating_df = X.data\n",
    "        self.ratings_table = X.data.pivot(index = 'userID', columns = 'movieID', values = 'rating').fillna(0)\n",
    "        ratings_table = self.ratings_table\n",
    "        \n",
    "        # demean\n",
    "        matrix = ratings_table.to_numpy()\n",
    "        user_ratings_mean = np.mean(matrix, axis = 1)\n",
    "        matrix = matrix - user_ratings_mean.reshape(-1, 1)\n",
    "        \n",
    "        # single value decomposition\n",
    "        u, sigma, vh = np.linalg.svd(matrix, full_matrices=False)\n",
    "        sigma = np.diag(sigma) # to ease multiplication\n",
    "        \n",
    "        pred_ratings = np.dot(np.dot(u, sigma), vh) + user_ratings_mean.reshape(-1, 1)\n",
    "        self.pred_df = pd.DataFrame(pred_ratings, columns = ratings_table.columns)\n",
    "            \n",
    "    def predict(self, user_id):\n",
    "        pred_df = self.pred_df\n",
    "        ratings_table = self.ratings_table\n",
    "        \n",
    "        return pred_df.iloc[user_id].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: Austin Powers: The Spy Who Shagged Me, ocena: 5.000000000000003\n",
      "Film: The Lord of the Rings: The Two Towers, ocena: 4.999999999999997\n",
      "Film: The Silence of the Lambs, ocena: 4.499999999999995\n",
      "Film: The Incredibles, ocena: 8.881784197001252e-15\n",
      "Film: Mrs. Doubtfire, ocena: 4.773959005888173e-15\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "rp = MatrixFactorizationPredictor()\n",
    "\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on GPU\n",
    "\n",
    "I failed this miserably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def similarity(data, user_ratings_w, p1, p2, min_values, threshold):\n",
    "        users1 = data[data[\"movieID\"] == p1][\"userID\"].values\n",
    "        users2 = data[data[\"movieID\"] == p2][\"userID\"].values\n",
    "        c_users = np.intersect1d(users1, users2)\n",
    "        \n",
    "        if len(c_users) < min_values:\n",
    "            return 0\n",
    "        \n",
    "        table = user_ratings_w[user_ratings_w.index.isin(c_users)]\n",
    "        m1 = table[p1]\n",
    "        m2 = table[p2]\n",
    "        \n",
    "        sim = 1 - distance.cosine(m1, m2)\n",
    "        \n",
    "        if sim <= threshold:\n",
    "            return 0\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarities(data, user_ratings, user_ratings_w, min_values=0, threshold=0):       \n",
    "        users = data.userID\n",
    "        movies = np.unique(data.movieID.values)\n",
    "\n",
    "        sims = {}\n",
    "        sim_table = pd.DataFrame(index=movies, columns=movies)\n",
    "        for pair in itertools.combinations(movies, 2):\n",
    "            m1, m2 = pair\n",
    "            sim = similarity(data, user_ratings, m1, m2, min_values, threshold)\n",
    "            \n",
    "            sims[(m1, m2)] = sim\n",
    "            sims[(m2, m1)] = sim\n",
    "            sim_table.loc[m1, m2] = sim\n",
    "            sim_table.loc[m2, m1] = sim\n",
    "        \n",
    "        return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def get_similarities_jit(data, user_ratings, user_ratings_w, min_values=0, threshold=0):       \n",
    "        users = data.userID\n",
    "        movies = np.unique(data.movieID.values)\n",
    "\n",
    "        sims = {}\n",
    "        sim_table = pd.DataFrame(index=movies, columns=movies)\n",
    "        for pair in itertools.combinations(movies, 2):\n",
    "            m1, m2 = pair\n",
    "            sim = similarity(data, user_ratings, m1, m2, min_values, threshold)\n",
    "            \n",
    "            sims[(m1, m2)] = sim\n",
    "            sims[(m2, m1)] = sim\n",
    "            sim_table.loc[m1, m2] = sim\n",
    "            sim_table.loc[m2, m1] = sim\n",
    "        \n",
    "        return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w(x, user_id, means):\n",
    "        return x - means[user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "\n",
    "class NN_Model(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(NN_Model, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return tf.nn.sigmoid(x)\n",
    "\n",
    "    \n",
    "    \n",
    "class NN_Predictor():\n",
    "    def __init__(self, movies_df):\n",
    "            self.movies_df = movies_df.data\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.data = X.data\n",
    "        data = self.data\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self, user_id):\n",
    "        data = self.data\n",
    "        movie_df = self.movies_df\n",
    "        \n",
    "        user_ids = data[\"userID\"].unique().tolist()\n",
    "        user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "        userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "        movie_ids = data[\"movieID\"].unique().tolist()\n",
    "        movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "        movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "        data[\"user\"] = data[\"userID\"].map(user2user_encoded)\n",
    "        data[\"movie\"] = data[\"movieID\"].map(movie2movie_encoded)\n",
    "\n",
    "        num_users = len(user2user_encoded)\n",
    "        num_movies = len(movie_encoded2movie)\n",
    "        data[\"rating\"] = data[\"rating\"].values.astype(np.float32)\n",
    "\n",
    "        # min and max ratings will be used to normalize the ratings later\n",
    "        min_rating = min(data[\"rating\"])\n",
    "        max_rating = max(data[\"rating\"])\n",
    "\n",
    "        data = data.sample(frac=1, random_state=42)\n",
    "        x = data[[\"user\", \"movie\"]].values\n",
    "\n",
    "        # normalize\n",
    "        y = data[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "\n",
    "        # train on 90% of the data and test on 10%.\n",
    "        train_indices = int(0.9 * data.shape[0])\n",
    "        x_train, x_val, y_train, y_val = (\n",
    "            x[:train_indices],\n",
    "            x[train_indices:],\n",
    "            y[:train_indices],\n",
    "            y[train_indices:],\n",
    "        )\n",
    "\n",
    "        model = NN_Model(num_users, num_movies, 50)\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            verbose=1,\n",
    "            validation_data=(x_val, y_val),\n",
    "        )\n",
    "        \n",
    "        movies_watched_by_user = data[data.userID == user_id]\n",
    "        \n",
    "        movies_not_watched = movie_df[\n",
    "            ~movie_df[\"id\"].isin(movies_watched_by_user.movieID.values)][\"id\"]\n",
    "        \n",
    "        movies_not_watched = list(\n",
    "        set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    "        )\n",
    "        \n",
    "        movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "        user_encoder = user2user_encoded.get(user_id)\n",
    "        \n",
    "        user_movie_array = np.hstack(\n",
    "            ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    "        )\n",
    "        \n",
    "        ratings = model.predict(user_movie_array).flatten()\n",
    "        top_ratings_indices = ratings.argsort()[::-1]\n",
    "        recommended_movie_ids = [\n",
    "            movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices                       \n",
    "        ]\n",
    "        \n",
    "        recommended_movies = movie_df[movie_df[\"id\"].isin(recommended_movie_ids)]\n",
    "        predictions = dict(zip(top_ratings_indices, ratings))\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "1362/1374 [============================>.] - ETA: 0s - loss: 0.5976WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "1374/1374 [==============================] - 2s 2ms/step - loss: 0.5973 - val_loss: 0.5730\n",
      "Epoch 2/5\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.5690 - val_loss: 0.5846\n",
      "Epoch 3/5\n",
      "1374/1374 [==============================] - 2s 1ms/step - loss: 0.5650 - val_loss: 0.5691\n",
      "Epoch 4/5\n",
      "1374/1374 [==============================] - 1s 1ms/step - loss: 0.5619 - val_loss: 0.5634\n",
      "Epoch 5/5\n",
      "1374/1374 [==============================] - 1s 716us/step - loss: 0.5575 - val_loss: 0.5635\n",
      "Film: Tom and Huck, ocena: 0.8419322967529297\n",
      "Film: Copycat, ocena: 0.7930474877357483\n",
      "Film: Sudden Death, ocena: 0.7905702590942383\n",
      "Film: Yao a yao yao dao waipo qiao, ocena: 0.7840534448623657\n",
      "Film: Dracula: Dead and Loving It, ocena: 0.7831463813781738\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "rp = NN_Predictor(md)\n",
    "\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "\n",
    "print()\n",
    "rec_items = rec.recommend(78, n=5, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "<b>NOTE</b> I trimmed the dataset to 1,000,000 items because it would take a very long time to use the entire thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class Word2VecPredictor:\n",
    "    def __init__(self):\n",
    "        orders = pd.read_csv('cart_data/orders.csv')\n",
    "        prior = pd.read_csv('cart_data/order_products__prior.csv')\n",
    "        products = pd.read_csv('cart_data/products.csv')\n",
    "        \n",
    "        _data = pd.merge(prior, products, on = ['product_id','product_id'])\n",
    "        self.data = pd.merge(_data, orders, on=['order_id','order_id'])[[\"order_id\", \"product_id\", \"product_name\", \"user_id\"]]\n",
    "        \n",
    "        # shorten for testing purposes, there are no null vlaues in dataset\n",
    "        self.data = self.data.iloc[:1000000]\n",
    "        self.data[\"product_id\"] = self.data[\"product_id\"].astype(str)\n",
    "        # 206209 users in total\n",
    "        self.users = self.data[\"user_id\"].unique().tolist()\n",
    "                \n",
    "\n",
    "        \n",
    "    def fit(self):\n",
    "        df = self.data\n",
    "            \n",
    "        # get 90% of users to train model\n",
    "        random.shuffle(self.users)\n",
    "        users_train = [self.users[i] for i in range(round(0.9*len(self.users)))]\n",
    "            \n",
    "        # split into train and test set\n",
    "        self.train = df[df['user_id'].isin(users_train)]\n",
    "        self.test = df[~df['user_id'].isin(users_train)]\n",
    "        train = self.train\n",
    "        test = self.test\n",
    "            \n",
    "        # lists to capture purchase history of the customers\n",
    "        # got tqdm because there's a lot of data and i wanna see the loop progress 'n stuff\n",
    "        purchases_train = []\n",
    "        for i in tqdm(users_train):\n",
    "            temp = train[train[\"user_id\"] == i][\"product_id\"].tolist()\n",
    "            purchases_train.append(temp)\n",
    "                \n",
    "        purchases_test = []\n",
    "        for i in tqdm(test['user_id'].unique()):\n",
    "            temp = test[test[\"user_id\"] == i][\"product_id\"].tolist()\n",
    "            purchases_test.append(temp)\n",
    "                \n",
    "        self.model = self.build_model(purchases_train, purchases_test)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def build_model(self, purchases_train, purchases_test):\n",
    "        model = Word2Vec(window = 10, sg = 1, hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            alpha=0.03, min_alpha=0.0007,\n",
    "            seed = 14)\n",
    "\n",
    "        model.build_vocab(purchases_train, progress_per=200)\n",
    "\n",
    "        model.train(purchases_train, total_examples = model.corpus_count, \n",
    "                            epochs=10, report_delay=1)\n",
    "            \n",
    "        model.init_sims(replace=True)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    def vec_predict(self, v, n):\n",
    "        products = self.train[[\"product_id\", \"product_name\"]]\n",
    "        products.drop_duplicates(inplace=True, subset='product_id', keep=\"last\")\n",
    "\n",
    "        # create product-ID and product-description dictionary\n",
    "        products_dict = products.groupby('product_id')['product_name'].apply(list).to_dict()\n",
    "        \n",
    "        # extract n most similar products for the input vector\n",
    "        return self.model.wv.similar_by_vector(v, topn = n)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def read_product(self, product_id):\n",
    "        return self.data[self.data[\"product_id\"] == product_id].iloc[0][\"product_name\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, product_id, n=5):\n",
    "        product_id = str(product_id)\n",
    "        preds = self.vec_predict(str(product_id), n)\n",
    "        preds = list(preds)\n",
    "        preds_dict = {}\n",
    "                \n",
    "        for pred in preds:\n",
    "            preds_dict[self.read_product(pred[0])] = pred[1]\n",
    "        \n",
    "        return preds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19654/19654 [00:36<00:00, 537.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2184/2184 [00:01<00:00, 1926.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Michigan Organic Kale\n",
      "{'Limes': 0.8007930517196655, 'Large Lemon': 0.7838623523712158, 'Organic Red Onion': 0.7832534909248352, 'Organic Strawberries': 0.7758601903915405, 'Extra Virgin Olive Oil': 0.7725867629051208}\n"
     ]
    }
   ],
   "source": [
    "pred = Word2VecPredictor()\n",
    "pred.fit()\n",
    "\n",
    "print(f\"Recommendations for {pred.read_product('28985')}\")\n",
    "print(pred.predict(\"28985\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class ClusterPredictor:\n",
    "    def fit(self, X):\n",
    "        self.ratings = X.data[[\"movieID\", \"userID\", \"rating\"]]\n",
    "        self.matrix = self.ratings.pivot_table(index=['userID'], columns=['movieID'], values='rating').fillna(0)  \n",
    "        cols = self.matrix.columns\n",
    "        fjalor = {}\n",
    "        \n",
    "        # a column represents a movie\n",
    "        for col in cols:\n",
    "            fjalor[col] = pd.arrays.SparseArray(self.matrix[col])\n",
    "        \n",
    "        sparseFrame = pd.DataFrame(fjalor)\n",
    "        sparse_ratings = csr_matrix(sparseFrame)\n",
    "        pred_sparse_1 = KMeans(n_clusters=12, algorithm='full').fit_predict(sparse_ratings)\n",
    "        \n",
    "        # get clusters of users\n",
    "        self.cluster = pd.concat([self.matrix.reset_index(), pd.DataFrame({'group': pred_sparse_1})], axis=1)  \n",
    "    \n",
    "    def get_user_cluster(self, user_id):\n",
    "        return self.cluster[self.cluster[\"userID\"] == user_id][\"group\"].item()\n",
    "    \n",
    "    def predict(self, user_id):\n",
    "        cluster_id = self.get_user_cluster(user_id)\n",
    "        user_cluster = self.cluster[self.cluster.group == cluster_id].drop(['group'], axis=1)\n",
    "        user_cluster = user_cluster.set_index(\"userID\")\n",
    "        \n",
    "        user_row = user_cluster[user_cluster.index == user_id]\n",
    "        user_rated = user_row.loc[:, (user_row != 0).any(axis=0)].T # remove empty columns\n",
    "        user_rated = user_rated.rename(columns={user_id: \"rating\"})\n",
    "        \n",
    "        user_rated = user_rated[\"rating\"].to_dict()\n",
    "        means = user_cluster.mean().to_dict()\n",
    "        \n",
    "        # user_rated replaces values in means\n",
    "        recs = {**means, **user_rated}\n",
    "        return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Film: The Silence of the Lambs, ocena: 3.793103448275862\n",
      "Film: The Usual Suspects, ocena: 3.6413793103448278\n",
      "Film: Shichinin no samurai, ocena: 3.1724137931034484\n",
      "Film: The Lord of the Rings: The Fellowship of the Ring, ocena: 2.7344827586206897\n",
      "Film: Die Hard, ocena: 2.679310344827586\n",
      "Film: Rain Man, ocena: 2.5724137931034483\n",
      "Film: The Fugitive, ocena: 2.537931034482759\n",
      "Film: Men in Black, ocena: 2.503448275862069\n",
      "Film: Gladiator, ocena: 2.4034482758620688\n",
      "Film: Indiana Jones and the Last Crusade, ocena: 2.396551724137931\n"
     ]
    }
   ],
   "source": [
    "md = MovieData('data/movies.dat')\n",
    "uim = UserItemData('data/user_ratedmovies.dat', min_ratings=1000)\n",
    "rp = ClusterPredictor()\n",
    "\n",
    "rec = Recommender(rp)\n",
    "rec.fit(uim)\n",
    "rec_items = rec.recommend(78, rec_seen=False)\n",
    "for idmovie, val in rec_items:\n",
    "    print(\"Film: {}, ocena: {}\".format(md.get_title(idmovie), val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
